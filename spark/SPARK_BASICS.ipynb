{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7f8ccc526890>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import Row\n",
    "from datetime import datetime\n",
    "#row is spark object use to represent single record in dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### convert python list into RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:484"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_data = sc.parallelize([1,'abc'])\n",
    "simple_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_data.first()#action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 'abc']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_data.collect()#action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 'abc']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_data.take(2)#action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = simple_data.toDF()\n",
    "#it give error bcoz simple_data has entity of different type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = sc.parallelize([[1,'abc'],[2,'xyz']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[5] at parallelize at PythonRDD.scala:484"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'abc'], [2, 'xyz']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = data.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_1: bigint, _2: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_1=1, _2=u'abc'), Row(_1=2, _2=u'xyz')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.collect()\n",
    "#we can use RDD's Operations on dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(_1=1, _2=u'abc')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first()\n",
    "#we can use RDD's Operations on dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_1=1, _2=u'abc')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(1)\n",
    "#we can use RDD's Operations on dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| _1| _2|\n",
      "+---+---+\n",
      "|  1|abc|\n",
      "|  2|xyz|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()\n",
    "#show() method return result in tabular format and column name is generated automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### If we want to create create dataframe with column name then we can use Row() object to give name to column in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "record = sc.parallelize([Row(id=1,name='abc'),\n",
    "                         Row(id=2,name='xyz')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[22] at parallelize at PythonRDD.scala:484"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=1, name='abc'), Row(id=2, name='xyz')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = record.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+\n",
      "| id|name|\n",
      "+---+----+\n",
      "|  1| abc|\n",
      "|  2| xyz|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complex Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "record = sc.parallelize([Row(\n",
    "                                col_list = [1,2,3],\n",
    "                                col_dict = {\"k1\":0},\n",
    "                                col_row = Row(1,2,3),\n",
    "                                col_time = datetime(2014,11,8)),\n",
    "                        Row(\n",
    "                                col_list = [4,5,6],\n",
    "                                col_dict = {\"k2\":0},\n",
    "                                col_row = Row(4,5,6),\n",
    "                                col_time = datetime(2014,11,8))\n",
    "                        \n",
    "                        \n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-------+--------------------+\n",
      "|    col_dict| col_list|col_row|            col_time|\n",
      "+------------+---------+-------+--------------------+\n",
      "|Map(k1 -> 0)|[1, 2, 3]|[1,2,3]|2014-11-08 00:00:...|\n",
      "|Map(k2 -> 0)|[4, 5, 6]|[4,5,6]|2014-11-08 00:00:...|\n",
      "+------------+---------+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = record.toDF()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQLCONTEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlcontext = SQLContext(sc)\n",
    "#it take sc object as input parameter\n",
    "#it is wrapper around sparkContext\n",
    "#provide additional SQL Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x7ffb41fbddd0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlcontext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sqlcontext.range(5)\n",
    "#range function of SQLCONTEXT create dataframe of one column id with 5 values in it from 0-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [('abc',1),\n",
    "        ('xyz',2)\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abc', 1), ('xyz', 2)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| _1| _2|\n",
      "+---+---+\n",
      "|abc|  1|\n",
      "|xyz|  2|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlcontext.createDataFrame(data).show()\n",
    "#it allow us to create dataframe directly from input data i.e data\n",
    "#instead of create RDD from Data then Create DataFrame from That RDD\n",
    "#here name of column is explicitly created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|NAME| Id|\n",
      "+----+---+\n",
      "| abc|  1|\n",
      "| xyz|  2|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlcontext.createDataFrame(data,['NAME','Id']).show()\n",
    "#here we give input data as well as name of column name\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### All operations Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "record = sc.parallelize([Row('[1,2,3]',\n",
    "                             '{\"k1\":0}',\n",
    "                             'Row(1,2,3)',\n",
    "                             'datetime(2014,11,8))')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "record = sc.parallelize([Row(1,2,3,4),\n",
    "                         Row(5,6,7,8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_name = Row('col_list','col_dict','col_row','col_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = record.map(lambda x : columns_name(*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[65] at RDD at PythonRDD.scala:49"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(col_list='[1,2,3]', col_dict='{\"k1\":0}', col_row='Row(1,2,3)', col_time='datetime(2014,11,8))')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### convert DataFrame to RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[65] at RDD at PythonRDD.scala:49"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'k1': 0}, {u'k2': 0}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.map(lambda x : x.col_dict).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|    col_dict|\n",
      "+------------+\n",
      "|Map(k1 -> 0)|\n",
      "|Map(k2 -> 0)|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('col_dict').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### DataFrame is not support map operation so to do opertaion on it we can use \"withColumn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-------+--------------------+\n",
      "|    col_dict| col_list|col_row|            col_time|\n",
      "+------------+---------+-------+--------------------+\n",
      "|Map(k1 -> 0)|[1, 2, 3]|[1,2,3]|2014-11-08 00:00:...|\n",
      "|Map(k2 -> 0)|[4, 5, 6]|[4,5,6]|2014-11-08 00:00:...|\n",
      "+------------+---------+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+\n",
      "| col_list|col|\n",
      "+---------+---+\n",
      "|[1, 2, 3]|  3|\n",
      "|[4, 5, 6]|  6|\n",
      "+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('col_list').withColumn(\"col\",df.col_list[0]+2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-------+--------------------+---+\n",
      "|    col_dict| col_list|col_row|            col_time|col|\n",
      "+------------+---------+-------+--------------------+---+\n",
      "|Map(k1 -> 0)|[1, 2, 3]|[1,2,3]|2014-11-08 00:00:...|  3|\n",
      "|Map(k2 -> 0)|[4, 5, 6]|[4,5,6]|2014-11-08 00:00:...|  6|\n",
      "+------------+---------+-------+--------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"col\",df.col_list[0]+2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-347974af44b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/hadoop/spark/python/pyspark/sql/dataframe.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    971\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             raise AttributeError(\n\u001b[0;32m--> 973\u001b[0;31m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[1;32m    974\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "df.map(lambda x : x).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-------+--------------------+\n",
      "|    col_dict|     list|col_row|            col_time|\n",
      "+------------+---------+-------+--------------------+\n",
      "|Map(k1 -> 0)|[1, 2, 3]|[1,2,3]|2014-11-08 00:00:...|\n",
      "|Map(k2 -> 0)|[4, 5, 6]|[4,5,6]|2014-11-08 00:00:...|\n",
      "+------------+---------+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed('col_list','list').show()\n",
    "#new name assign and new data frame is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "| col_list|     list|\n",
      "+---------+---------+\n",
      "|[1, 2, 3]|[1, 2, 3]|\n",
      "|[4, 5, 6]|[4, 5, 6]|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('col_list',df.col_list.alias('list')).show()\n",
    "#alias method is use to give name to column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We can convert Spark DataFrame to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[col_dict: map<string,bigint>, col_list: array<bigint>, col_row: struct<_1:bigint,_2:bigint,_3:bigint>, col_time: timestamp]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_pandas = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_dict</th>\n",
       "      <th>col_list</th>\n",
       "      <th>col_row</th>\n",
       "      <th>col_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{u'k1': 0}</td>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "      <td>2014-11-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{u'k2': 0}</td>\n",
       "      <td>[4, 5, 6]</td>\n",
       "      <td>(4, 5, 6)</td>\n",
       "      <td>2014-11-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     col_dict   col_list    col_row   col_time\n",
       "0  {u'k1': 0}  [1, 2, 3]  (1, 2, 3) 2014-11-08\n",
       "1  {u'k2': 0}  [4, 5, 6]  (4, 5, 6) 2014-11-08"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas\n",
    "#Pandas Dataframe are in-memory on single machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### convert Pandas DataFrame to Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-------+-------------------+\n",
      "|    col_dict| col_list|col_row|           col_time|\n",
      "+------------+---------+-------+-------------------+\n",
      "|Map(k1 -> 0)|[1, 2, 3]|[1,2,3]|1415404800000000000|\n",
      "|Map(k2 -> 0)|[4, 5, 6]|[4,5,6]|1415404800000000000|\n",
      "+------------+---------+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark = sqlcontext.createDataFrame(df_pandas).show()\n",
    "#this Soark dataFrame is spread across multiple data node of Spark Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPARK 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPARKSESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Crime_Data').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = spark.read.format(\"csv\")\\\n",
    "                .option(\"header\",\"true\")\\\n",
    "                .load(\"file:///home/icpl12900/Desktop/assignments/Spark_data/london_crime_by_lsoa.csv\")\n",
    "        \n",
    "#.load read csv file\n",
    "#.read allow u to read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- lsoa_code: string (nullable = true)\n",
      " |-- borough: string (nullable = true)\n",
      " |-- major_category: string (nullable = true)\n",
      " |-- minor_category: string (nullable = true)\n",
      " |-- value: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+--------------------+-----+----+-----+\n",
      "|lsoa_code|             borough|      major_category|      minor_category|value|year|month|\n",
      "+---------+--------------------+--------------------+--------------------+-----+----+-----+\n",
      "|E01001116|             Croydon|            Burglary|Burglary in Other...|    0|2016|   11|\n",
      "|E01001646|           Greenwich|Violence Against ...|      Other violence|    0|2016|   11|\n",
      "|E01000677|             Bromley|Violence Against ...|      Other violence|    0|2015|    5|\n",
      "|E01003774|           Redbridge|            Burglary|Burglary in Other...|    0|2016|    3|\n",
      "|E01004563|          Wandsworth|             Robbery|   Personal Property|    0|2008|    6|\n",
      "|E01001320|              Ealing|  Theft and Handling|         Other Theft|    0|2012|    5|\n",
      "|E01001342|              Ealing|Violence Against ...|    Offensive Weapon|    0|2010|    7|\n",
      "|E01002633|            Hounslow|             Robbery|   Personal Property|    0|2013|    4|\n",
      "|E01003496|              Newham|     Criminal Damage|Criminal Damage T...|    0|2013|    9|\n",
      "|E01004177|              Sutton|  Theft and Handling|Theft/Taking of P...|    1|2016|    8|\n",
      "|E01001985|            Haringey|  Theft and Handling|Motor Vehicle Int...|    0|2013|   12|\n",
      "|E01003076|             Lambeth|Violence Against ...|      Other violence|    0|2015|    4|\n",
      "|E01003852|Richmond upon Thames|             Robbery|   Personal Property|    0|2014|    1|\n",
      "|E01004547|          Wandsworth|Violence Against ...|    Offensive Weapon|    0|2011|   10|\n",
      "|E01002398|          Hillingdon|  Theft and Handling|Theft/Taking Of M...|    0|2016|    2|\n",
      "|E01002358|            Havering|Violence Against ...|        Wounding/GBH|    0|2012|    2|\n",
      "|E01000086|Barking and Dagenham|  Theft and Handling|  Other Theft Person|    1|2009|    5|\n",
      "|E01003708|           Redbridge|Violence Against ...|      Common Assault|    0|2009|    6|\n",
      "|E01002945|Kingston upon Thames|  Theft and Handling|    Theft From Shops|    0|2016|   11|\n",
      "|E01004195|              Sutton|               Drugs| Possession Of Drugs|    0|2009|   10|\n",
      "+---------+--------------------+--------------------+--------------------+-----+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(lsoa_code=u'E01001116', borough=u'Croydon', major_category=u'Burglary', minor_category=u'Burglary in Other Buildings', value=u'0', year=u'2016', month=u'11'),\n",
       " Row(lsoa_code=u'E01001646', borough=u'Greenwich', major_category=u'Violence Against the Person', minor_category=u'Other violence', value=u'0', year=u'2016', month=u'11')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)\n",
    "#it return Result in form of RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------------------+-----+----+-----+\n",
      "|lsoa_code|  borough|      major_category|      minor_category|value|year|month|\n",
      "+---------+---------+--------------------+--------------------+-----+----+-----+\n",
      "|E01001116|  Croydon|            Burglary|Burglary in Other...|    0|2016|   11|\n",
      "|E01001646|Greenwich|Violence Against ...|      Other violence|    0|2016|   11|\n",
      "+---------+---------+--------------------+--------------------+-----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.limit(2).show()\n",
    "#it return result in form of DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13490604"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[lsoa_code: string, borough: string, major_category: string, minor_category: string, value: string, year: string, month: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             borough|\n",
      "+--------------------+\n",
      "|             Croydon|\n",
      "|          Wandsworth|\n",
      "|              Bexley|\n",
      "|             Lambeth|\n",
      "|Barking and Dagenham|\n",
      "|              Camden|\n",
      "|           Greenwich|\n",
      "|              Newham|\n",
      "|       Tower Hamlets|\n",
      "|            Hounslow|\n",
      "|              Barnet|\n",
      "|              Harrow|\n",
      "|Kensington and Ch...|\n",
      "|           Islington|\n",
      "|               Brent|\n",
      "|            Haringey|\n",
      "|             Bromley|\n",
      "|              Merton|\n",
      "|         Westminster|\n",
      "|             Hackney|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('borough').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select('borough').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+--------------+--------------------+-----+----+-----+\n",
      "|lsoa_code|borough|major_category|      minor_category|value|year|month|\n",
      "+---------+-------+--------------+--------------------+-----+----+-----+\n",
      "|E01001116|Croydon|      Burglary|Burglary in Other...|    0|2016|   11|\n",
      "|E01001029|Croydon|         Drugs| Possession Of Drugs|    0|2010|   12|\n",
      "+---------+-------+--------------+--------------------+-----+----+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.filter(data['borough'] == 'Croydon').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------------+--------------------+-----+----+-----+\n",
      "|lsoa_code|   borough|      major_category|      minor_category|value|year|month|\n",
      "+---------+----------+--------------------+--------------------+-----+----+-----+\n",
      "|E01002634|  Hounslow|     Criminal Damage|Criminal Damage T...|    0|2015|    2|\n",
      "|E01002360|  Havering|    Fraud or Forgery|  Counted per Victim|    0|2015|   11|\n",
      "|E01002122|    Harrow|    Fraud or Forgery|Other Fraud & For...|    0|2015|    2|\n",
      "|E01002804| Islington|  Theft and Handling|Theft/Taking Of M...|    0|2016|    6|\n",
      "|E01001807|   Hackney|  Theft and Handling|  Other Theft Person|    0|2016|    8|\n",
      "|E01003625|    Newham|Violence Against ...|      Other violence|    0|2015|    3|\n",
      "|E01002231|    Harrow|               Drugs| Possession Of Drugs|    0|2016|   11|\n",
      "|E01000829|   Bromley|     Criminal Damage|Criminal Damage T...|    0|2015|    9|\n",
      "|E01032562|   Bromley|     Criminal Damage|Other Criminal Da...|    0|2015|   12|\n",
      "|E01033739| Greenwich|     Criminal Damage|Criminal Damage T...|    0|2016|   10|\n",
      "|E01003435|    Merton|Violence Against ...|          Harassment|    1|2015|    6|\n",
      "|E01002650|  Hounslow|     Criminal Damage|Other Criminal Da...|    1|2016|    2|\n",
      "|E01001023|   Croydon|Violence Against ...|        Wounding/GBH|    0|2016|   10|\n",
      "|E01004614|Wandsworth|Violence Against ...|    Offensive Weapon|    0|2016|    2|\n",
      "|E01002793| Islington|Violence Against ...|    Offensive Weapon|    0|2016|    5|\n",
      "|E01002793| Islington|Violence Against ...|    Offensive Weapon|    0|2016|    5|\n",
      "|E01003780| Redbridge|Violence Against ...|          Harassment|    0|2015|    6|\n",
      "|E01003304|  Lewisham|  Theft and Handling|Handling Stolen G...|    0|2016|    7|\n",
      "|E01000713|   Bromley|  Theft and Handling|         Other Theft|    1|2016|   12|\n",
      "|E01000941|    Camden|  Theft and Handling|Theft From Motor ...|    0|2015|   12|\n",
      "+---------+----------+--------------------+--------------------+-----+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_2015_2016 = data.filter(data['year'].isin(\"2015\",\"2016\"))\n",
    "data_2015_2016.sample(True,fraction=0.1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+--------------------+--------------------+-----+----+-----+\n",
      "|lsoa_code|       borough|      major_category|      minor_category|value|year|month|\n",
      "+---------+--------------+--------------------+--------------------+-----+----+-----+\n",
      "|E01004346|Waltham Forest|  Theft and Handling|Motor Vehicle Int...|    0|2016|    3|\n",
      "|E01001807|       Hackney|  Theft and Handling|  Other Theft Person|    0|2016|    8|\n",
      "|E01000486|         Brent|               Drugs| Possession Of Drugs|    0|2015|   11|\n",
      "|E01000353|        Bexley|Violence Against ...| Assault with Injury|    0|2015|    6|\n",
      "|E01000829|       Bromley|     Criminal Damage|Criminal Damage T...|    0|2015|    9|\n",
      "|E01002367|      Havering|Other Notifiable ...|    Other Notifiable|    0|2016|    6|\n",
      "|E01002426|    Hillingdon|Violence Against ...|        Wounding/GBH|    0|2016|    9|\n",
      "|E01001208|        Ealing|  Theft and Handling|  Other Theft Person|    0|2015|    8|\n",
      "|E01001846|       Hackney|Violence Against ...|          Harassment|    0|2015|    3|\n",
      "|E01003743|     Redbridge|Other Notifiable ...|      Going Equipped|    0|2015|    9|\n",
      "|E01001455|       Enfield|               Drugs|    Drug Trafficking|    0|2016|   12|\n",
      "|E01000246|        Barnet|             Robbery|   Business Property|    0|2015|    8|\n",
      "|E01004066|     Southwark|Violence Against ...|        Wounding/GBH|    1|2015|    1|\n",
      "|E01004614|    Wandsworth|Violence Against ...|    Offensive Weapon|    0|2016|    2|\n",
      "|E01004321| Tower Hamlets|Violence Against ...|        Wounding/GBH|    1|2015|    9|\n",
      "|E01000125|        Barnet|Other Notifiable ...|    Other Notifiable|    0|2015|    8|\n",
      "|E01003321|      Lewisham|    Fraud or Forgery|Other Fraud & For...|    0|2015|    6|\n",
      "|E01002364|      Havering|  Theft and Handling|         Other Theft|    0|2015|    5|\n",
      "|E01000907|        Camden|     Criminal Damage|Criminal Damage T...|    0|2015|    3|\n",
      "|E01000713|       Bromley|  Theft and Handling|         Other Theft|    1|2016|   12|\n",
      "+---------+--------------+--------------------+--------------------+-----+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_2015_2016 = data.filter(data['year'].isin(\"2015\",\"2016\"))\n",
    "data_2015_2016.sample(False,fraction=0.1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+--------------------+-----+----+-----+\n",
      "|lsoa_code|             borough|      major_category|      minor_category|value|year|month|\n",
      "+---------+--------------------+--------------------+--------------------+-----+----+-----+\n",
      "|E01001116|             Croydon|            Burglary|Burglary in Other...|    0|2016|   11|\n",
      "|E01001646|           Greenwich|Violence Against ...|      Other violence|    0|2016|   11|\n",
      "|E01000677|             Bromley|Violence Against ...|      Other violence|    0|2015|    5|\n",
      "|E01003774|           Redbridge|            Burglary|Burglary in Other...|    0|2016|    3|\n",
      "|E01004177|              Sutton|  Theft and Handling|Theft/Taking of P...|    1|2016|    8|\n",
      "|E01003076|             Lambeth|Violence Against ...|      Other violence|    0|2015|    4|\n",
      "|E01002398|          Hillingdon|  Theft and Handling|Theft/Taking Of M...|    0|2016|    2|\n",
      "|E01002945|Kingston upon Thames|  Theft and Handling|    Theft From Shops|    0|2016|   11|\n",
      "|E01001972|            Haringey|Violence Against ...|        Wounding/GBH|    0|2015|   12|\n",
      "|E01003325|            Lewisham|Violence Against ...|      Common Assault|    0|2016|    2|\n",
      "|E01002634|            Hounslow|     Criminal Damage|Criminal Damage T...|    0|2015|    2|\n",
      "|E01000733|             Bromley|     Criminal Damage|Criminal Damage T...|    1|2016|    4|\n",
      "|E01002006|            Haringey|     Criminal Damage|Criminal Damage T...|    0|2016|   12|\n",
      "|E01003947|           Southwark|               Drugs| Possession Of Drugs|    0|2015|    3|\n",
      "|E01002360|            Havering|    Fraud or Forgery|  Counted per Victim|    0|2015|   11|\n",
      "|E01004436|      Waltham Forest|Other Notifiable ...|      Going Equipped|    0|2015|    2|\n",
      "|E01001206|              Ealing|             Robbery|   Personal Property|    0|2015|    7|\n",
      "|E01000606|               Brent|  Theft and Handling|Motor Vehicle Int...|    0|2015|    9|\n",
      "|E01033083|            Hounslow|Violence Against ...|        Wounding/GBH|    2|2015|    8|\n",
      "|E01003989|           Southwark|  Theft and Handling|    Theft From Shops|    4|2016|    8|\n",
      "+---------+--------------------+--------------------+--------------------+-----+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_2015_2016 = data.filter(data['year'].isin(\"2015\",\"2016\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spark sampling functions allows to take different samples following distributions or only take a couple of them. In Spark, there are two sampling operations, the transformation sample and the action takeSample. By using a transformation we can tell Spark to apply successive transformation on a sample of a given RDD. By using an action we retrieve a given sample and we can have it in local memory to be used by any other standard library.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby and AGG\n",
    "###### In RDD we can use \"GROUPBY\" only on \"PAIR RDD\" and groupby with key only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_month = data.filter(data['year']=='2014')\\\n",
    "                    .groupBy('month')\\\n",
    "                    .agg({\"value\":\"sum\"})\\\n",
    "                    .withColumnRenamed(\"sum(value)\",\"monthly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|month|monthly|\n",
      "+-----+-------+\n",
      "|    7|58564.0|\n",
      "|   11|59704.0|\n",
      "+-----+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "group_month.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total = group_month.agg({\"monthly\":\"sum\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|sum(monthly)|\n",
      "+------------+\n",
      "|    680183.0|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_sum = total.collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "680183.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "percentage = group_month.select(['month','monthly']).withColumn('month_\"percent',func.round(((group_month.monthly / total_sum)*100) ,2))\n",
    "#new column have name monthly which is created with \"withColumn\"\n",
    "#if we give same name of column which is in dataframe in \"withColumn\" then it replace old column with new column value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- month: string (nullable = true)\n",
      " |-- monthly: double (nullable = true)\n",
      " |-- month_\"percent: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "percentage.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+--------------+\n",
      "|month|monthly|month_\"percent|\n",
      "+-----+-------+--------------+\n",
      "|    7|58564.0|          8.61|\n",
      "|   11|59704.0|          8.78|\n",
      "+-----+-------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "percentage.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "| sum(month)|\n",
      "+-----------+\n",
      "|8.7688926E7|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.agg({\"month\":\"sum\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+--------------------+-----+----+-----+\n",
      "|lsoa_code|             borough|      major_category|      minor_category|value|year|month|\n",
      "+---------+--------------------+--------------------+--------------------+-----+----+-----+\n",
      "|E01000389|              Bexley|               Drugs|    Drug Trafficking|    0|2009|    9|\n",
      "|E01002050|            Haringey|    Fraud or Forgery|Other Fraud & For...|    0|2016|    9|\n",
      "|E01002191|              Harrow|     Criminal Damage|Criminal Damage T...|    0|2011|    9|\n",
      "|E01000194|              Barnet|Violence Against ...|    Offensive Weapon|    0|2009|    9|\n",
      "|E01001423|             Enfield|Violence Against ...|          Harassment|    0|2012|    9|\n",
      "|E01000491|               Brent|  Theft and Handling|Handling Stolen G...|    0|2012|    9|\n",
      "|E01002701|           Islington|  Theft and Handling|Theft From Motor ...|    0|2010|    9|\n",
      "|E01003887|Richmond upon Thames|               Drugs| Possession Of Drugs|    0|2014|    9|\n",
      "|E01003576|              Newham|  Theft and Handling|Motor Vehicle Int...|    1|2014|    9|\n",
      "|E01000339|              Bexley|               Drugs|    Drug Trafficking|    0|2012|    9|\n",
      "|E01000551|               Brent|Violence Against ...|      Common Assault|    1|2011|    9|\n",
      "|E01003303|            Lewisham|  Theft and Handling|  Other Theft Person|    5|2016|    9|\n",
      "|E01001116|             Croydon|Violence Against ...|        Wounding/GBH|    1|2013|    9|\n",
      "|E01004715|         Westminster|Violence Against ...|      Other violence|    0|2013|    9|\n",
      "|E01003335|            Lewisham|Other Notifiable ...|    Other Notifiable|    1|2009|    9|\n",
      "|E01002669|            Hounslow|     Criminal Damage|Criminal Damage T...|    0|2016|    9|\n",
      "|E01000205|              Barnet|            Burglary|Burglary in Other...|    0|2012|    9|\n",
      "|E01002264|            Havering|            Burglary|Burglary in Other...|    1|2012|    9|\n",
      "|E01004003|           Southwark|Violence Against ...| Assault with Injury|    3|2011|    9|\n",
      "|E01000298|              Barnet|  Theft and Handling|    Theft From Shops|    0|2010|    9|\n",
      "+---------+--------------------+--------------------+--------------------+-----+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.orderBy(data['month'].desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Drugs|\n",
      "+-----+\n",
      "|32616|\n",
      "|29160|\n",
      "|35424|\n",
      "|37368|\n",
      "|42336|\n",
      "|44064|\n",
      "|22140|\n",
      "|32616|\n",
      "|23004|\n",
      "|43740|\n",
      "|46980|\n",
      "|26244|\n",
      "|36504|\n",
      "|34128|\n",
      "|38772|\n",
      "|41580|\n",
      "|  756|\n",
      "|26784|\n",
      "|45144|\n",
      "|31212|\n",
      "+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.crosstab('borough','major_category').select('Drugs').show()\n",
    "#borough is Y-AXIS and major_category is X-AXIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "players =  spark.read.format(\"csv\")\\\n",
    "                .option(\"header\",\"true\")\\\n",
    "                .load(\"file:///home/icpl12900/Desktop/assignments/Spark_data/player.csv\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "player_attribute = spark.read.format(\"csv\")\\\n",
    "                .option(\"header\",\"true\")\\\n",
    "                .load(\"file:///home/icpl12900/Desktop/assignments/Spark_data/player_attributes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- player_fifa_api_id: string (nullable = true)\n",
      " |-- player_api_id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- overall_rating: string (nullable = true)\n",
      " |-- potential: string (nullable = true)\n",
      " |-- preferred_foot: string (nullable = true)\n",
      " |-- attacking_work_rate: string (nullable = true)\n",
      " |-- defensive_work_rate: string (nullable = true)\n",
      " |-- crossing: string (nullable = true)\n",
      " |-- finishing: string (nullable = true)\n",
      " |-- heading_accuracy: string (nullable = true)\n",
      " |-- short_passing: string (nullable = true)\n",
      " |-- volleys: string (nullable = true)\n",
      " |-- dribbling: string (nullable = true)\n",
      " |-- curve: string (nullable = true)\n",
      " |-- free_kick_accuracy: string (nullable = true)\n",
      " |-- long_passing: string (nullable = true)\n",
      " |-- ball_control: string (nullable = true)\n",
      " |-- acceleration: string (nullable = true)\n",
      " |-- sprint_speed: string (nullable = true)\n",
      " |-- agility: string (nullable = true)\n",
      " |-- reactions: string (nullable = true)\n",
      " |-- balance: string (nullable = true)\n",
      " |-- shot_power: string (nullable = true)\n",
      " |-- jumping: string (nullable = true)\n",
      " |-- stamina: string (nullable = true)\n",
      " |-- strength: string (nullable = true)\n",
      " |-- long_shots: string (nullable = true)\n",
      " |-- aggression: string (nullable = true)\n",
      " |-- interceptions: string (nullable = true)\n",
      " |-- positioning: string (nullable = true)\n",
      " |-- vision: string (nullable = true)\n",
      " |-- penalties: string (nullable = true)\n",
      " |-- marking: string (nullable = true)\n",
      " |-- standing_tackle: string (nullable = true)\n",
      " |-- sliding_tackle: string (nullable = true)\n",
      " |-- gk_diving: string (nullable = true)\n",
      " |-- gk_handling: string (nullable = true)\n",
      " |-- gk_kicking: string (nullable = true)\n",
      " |-- gk_positioning: string (nullable = true)\n",
      " |-- gk_reflexes: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "player_attribute.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- player_api_id: string (nullable = true)\n",
      " |-- player_name: string (nullable = true)\n",
      " |-- player_fifa_api_id: string (nullable = true)\n",
      " |-- birthday: string (nullable = true)\n",
      " |-- height: string (nullable = true)\n",
      " |-- weight: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "players.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function pyspark.sql.functions.udf>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year_extract_udf = udf(lambda date : date.split('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_player_attribute = player_attribute.withColumn('year' , year_extract_udf(player_attribute.date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- player_fifa_api_id: string (nullable = true)\n",
      " |-- player_api_id: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- overall_rating: string (nullable = true)\n",
      " |-- potential: string (nullable = true)\n",
      " |-- preferred_foot: string (nullable = true)\n",
      " |-- attacking_work_rate: string (nullable = true)\n",
      " |-- defensive_work_rate: string (nullable = true)\n",
      " |-- crossing: string (nullable = true)\n",
      " |-- finishing: string (nullable = true)\n",
      " |-- heading_accuracy: string (nullable = true)\n",
      " |-- short_passing: string (nullable = true)\n",
      " |-- volleys: string (nullable = true)\n",
      " |-- dribbling: string (nullable = true)\n",
      " |-- curve: string (nullable = true)\n",
      " |-- free_kick_accuracy: string (nullable = true)\n",
      " |-- long_passing: string (nullable = true)\n",
      " |-- ball_control: string (nullable = true)\n",
      " |-- acceleration: string (nullable = true)\n",
      " |-- sprint_speed: string (nullable = true)\n",
      " |-- agility: string (nullable = true)\n",
      " |-- reactions: string (nullable = true)\n",
      " |-- balance: string (nullable = true)\n",
      " |-- shot_power: string (nullable = true)\n",
      " |-- jumping: string (nullable = true)\n",
      " |-- stamina: string (nullable = true)\n",
      " |-- strength: string (nullable = true)\n",
      " |-- long_shots: string (nullable = true)\n",
      " |-- aggression: string (nullable = true)\n",
      " |-- interceptions: string (nullable = true)\n",
      " |-- positioning: string (nullable = true)\n",
      " |-- vision: string (nullable = true)\n",
      " |-- penalties: string (nullable = true)\n",
      " |-- marking: string (nullable = true)\n",
      " |-- standing_tackle: string (nullable = true)\n",
      " |-- sliding_tackle: string (nullable = true)\n",
      " |-- gk_diving: string (nullable = true)\n",
      " |-- gk_handling: string (nullable = true)\n",
      " |-- gk_kicking: string (nullable = true)\n",
      " |-- gk_positioning: string (nullable = true)\n",
      " |-- gk_reflexes: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_player_attribute.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pa_2016 = new_player_attribute.filter(new_player_attribute.year == 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-------------+-------------------+--------------+---------+--------------+-------------------+-------------------+--------+---------+----------------+-------------+-------+---------+-----+------------------+------------+------------+------------+------------+-------+---------+-------+----------+-------+-------+--------+----------+----------+-------------+-----------+------+---------+-------+---------------+--------------+---------+-----------+----------+--------------+-----------+----+\n",
      "| id|player_fifa_api_id|player_api_id|               date|overall_rating|potential|preferred_foot|attacking_work_rate|defensive_work_rate|crossing|finishing|heading_accuracy|short_passing|volleys|dribbling|curve|free_kick_accuracy|long_passing|ball_control|acceleration|sprint_speed|agility|reactions|balance|shot_power|jumping|stamina|strength|long_shots|aggression|interceptions|positioning|vision|penalties|marking|standing_tackle|sliding_tackle|gk_diving|gk_handling|gk_kicking|gk_positioning|gk_reflexes|year|\n",
      "+---+------------------+-------------+-------------------+--------------+---------+--------------+-------------------+-------------------+--------+---------+----------------+-------------+-------+---------+-----+------------------+------------+------------+------------+------------+-------+---------+-------+----------+-------+-------+--------+----------+----------+-------------+-----------+------+---------+-------+---------------+--------------+---------+-----------+----------+--------------+-----------+----+\n",
      "|  1|            218353|       505942|2016-02-18 00:00:00|            67|       71|         right|             medium|             medium|      49|       44|              71|           61|     44|       51|   45|                39|          64|          49|          60|          64|     59|       47|     65|        55|     58|     54|      76|        35|        71|           70|         45|    54|       48|     65|             69|            69|        6|         11|        10|             8|          8|2016|\n",
      "|  6|            189615|       155782|2016-04-21 00:00:00|            74|       76|          left|               high|             medium|      80|       53|              58|           71|     40|       73|   70|                69|          68|          71|          79|          78|     78|       67|     90|        71|     85|     79|      56|        62|        68|           67|         60|    66|       59|     76|             75|            78|       14|          7|         9|             9|         12|2016|\n",
      "+---+------------------+-------------+-------------------+--------------+---------+--------------+-------------------+-------------------+--------+---------+----------------+-------------+-------+---------+-----+------------------+------------+------------+------------+------------+-------+---------+-------+----------+-------+-------+--------+----------+----------+-------------+-----------+------+---------+-------+---------------+--------------+---------+-----------+----------+--------------+-----------+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pa_2016.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pa_striker_2016 = pa_2016.groupBy('player_api_id').\\\n",
    "                        agg({\"finishing\" : 'avg',\n",
    "                            'shot_power':'avg',\n",
    "                            'acceleration':'avg'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- player_api_id: string (nullable = true)\n",
      " |-- avg(finishing): double (nullable = true)\n",
      " |-- avg(acceleration): double (nullable = true)\n",
      " |-- avg(shot_power): double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pa_striker_2016.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pa_striker_2016=pa_striker_2016.withColumnRenamed('avg(finishing)','finishing')\\\n",
    "              .withColumnRenamed('avg(acceleration)','acceleration')\\\n",
    "              .withColumnRenamed('avg(shot_power)','shot_power')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- player_api_id: string (nullable = true)\n",
      " |-- finishing: double (nullable = true)\n",
      " |-- acceleration: double (nullable = true)\n",
      " |-- shot_power: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pa_striker_2016.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finishing = 1\n",
    "acceleration = 2\n",
    "shot_power = 1\n",
    "total = finishing + acceleration + shot_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "striker = pa_striker_2016.withColumn(\"striker_grade\" , (pa_striker_2016.finishing * finishing +\\\n",
    "                                                       pa_striker_2016.acceleration * acceleration +\\\n",
    "                                                       pa_striker_2016.shot_power * shot_power)/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- player_api_id: string (nullable = true)\n",
      " |-- finishing: double (nullable = true)\n",
      " |-- acceleration: double (nullable = true)\n",
      " |-- shot_power: double (nullable = true)\n",
      " |-- striker_grade: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "striker.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "striker = striker.sort(striker.striker_grade.desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+------------+----------+-------------+\n",
      "|player_api_id|finishing|acceleration|shot_power|striker_grade|\n",
      "+-------------+---------+------------+----------+-------------+\n",
      "|        37412|     90.0|        92.0|      87.0|        90.25|\n",
      "|        38817|     88.0|        90.0|      88.5|       89.125|\n",
      "|       150565|     88.0|        95.0|      78.0|         89.0|\n",
      "|        31921|     81.0|        93.0|      87.0|         88.5|\n",
      "|        30834|     85.0|        90.0|      86.0|        87.75|\n",
      "+-------------+---------+------------+----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "striker.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "striker=striker.drop('finishing','acceleration','shot_power')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "|player_api_id|striker_grade|\n",
      "+-------------+-------------+\n",
      "|        37412|        90.25|\n",
      "|        38817|       89.125|\n",
      "+-------------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "striker.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- player_api_id: string (nullable = true)\n",
      " |-- player_name: string (nullable = true)\n",
      " |-- player_fifa_api_id: string (nullable = true)\n",
      " |-- birthday: string (nullable = true)\n",
      " |-- height: string (nullable = true)\n",
      " |-- weight: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "players.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_striker = striker.join(players,players.player_api_id == striker.player_api_id )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+----+-------------+-------------+------------------+-------------------+------+------+\n",
      "|player_api_id|striker_grade|  id|player_api_id|  player_name|player_fifa_api_id|           birthday|height|weight|\n",
      "+-------------+-------------+----+-------------+-------------+------------------+-------------------+------+------+\n",
      "|        37412|        90.25|9674|        37412|Sergio Aguero|            153079|1988-06-02 00:00:00|172.72|   163|\n",
      "|        38817|       89.125|1581|        38817| Carlos Tevez|            143001|1984-02-05 00:00:00|172.72|   157|\n",
      "+-------------+-------------+----+-------------+-------------+------------------+-------------------+------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_striker.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_striker = striker.join(players,['player_api_id'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+----+-------------+------------------+-------------------+------+------+\n",
      "|player_api_id|striker_grade|  id|  player_name|player_fifa_api_id|           birthday|height|weight|\n",
      "+-------------+-------------+----+-------------+------------------+-------------------+------+------+\n",
      "|        37412|        90.25|9674|Sergio Aguero|            153079|1988-06-02 00:00:00|172.72|   163|\n",
      "|        38817|       89.125|1581| Carlos Tevez|            143001|1984-02-05 00:00:00|172.72|   157|\n",
      "+-------------+-------------+----+-------------+------------------+-------------------+------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_striker.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BROADCAST VARIABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHEN DATASETS IS HUGE THEN JOIN OPERATIONS ON THAT DATASET IS VERY HEAVY OPERATION. BCOZ DATASETS ARE DISTRIBUTE ACROSS NODES IN CLUSTER. SO USE BROADCAST IN WHICH ONE DATASET WHICH IS SMALL IS COPY TO WORKER NODE AND JOIN PRFORM OVER THERE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "striker_details = players.select('player_api_id' ,'player_name').\\\n",
    "                            join(\n",
    "                                    broadcast(striker),\n",
    "                                    ['player_api_id'],\n",
    "                                    'inner' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+-----------------+\n",
      "|player_api_id|       player_name|    striker_grade|\n",
      "+-------------+------------------+-----------------+\n",
      "|       505942|Aaron Appindangoye|            54.75|\n",
      "|       155782|   Aaron Cresswell|70.41666666666666|\n",
      "+-------------+------------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "striker_details.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACCUMULATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HIGH HEADING ACCURACY DIVIDED BY BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "players_heading_acc = player_attribute.select('player_api_id','heading_accuracy').\\\n",
    "                                       join(\n",
    "                                            broadcast(players),\n",
    "                                                 ['player_api_id'],\n",
    "                                                'inner' \n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- player_api_id: string (nullable = true)\n",
      " |-- heading_accuracy: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- player_name: string (nullable = true)\n",
      " |-- player_fifa_api_id: string (nullable = true)\n",
      " |-- birthday: string (nullable = true)\n",
      " |-- height: string (nullable = true)\n",
      " |-- weight: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "players_heading_acc.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### HEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "short = spark.sparkContext.accumulator(0)\n",
    "medium = spark.sparkContext.accumulator(0)\n",
    "tall = spark.sparkContext.accumulator(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_player_height(row):\n",
    "    height = float(row.height)\n",
    "    if (height<=175):\n",
    "        short.add(1)\n",
    "    elif (height <= 195):\n",
    "        medium.add(1)\n",
    "    else:\n",
    "        tall.add(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "players_heading_acc.foreach(lambda x : count_player_height(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19204, 161369, 187383]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_players = [short.value,\n",
    "              medium.value,\n",
    "              tall.value]\n",
    "all_players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### heading_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "short_ha = spark.sparkContext.accumulator(0)\n",
    "medium_ha = spark.sparkContext.accumulator(0)\n",
    "tall_ha = spark.sparkContext.accumulator(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_player_headingAccuracy(row):\n",
    "    head = row.heading_accuracy\n",
    "    if(head>=75 and head<=175):\n",
    "        short_ha.add(1)\n",
    "    elif (head <= 195):\n",
    "        medium_ha.add(1)\n",
    "    else:\n",
    "        tall_ha.add(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "players_heading_acc.foreach(lambda x : count_player_headingAccuracy(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1672, 836, 549426]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_players_heading = [short_ha.value,\n",
    "                      medium_ha.value,\n",
    "                      tall_ha.value]\n",
    "all_players_heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 200]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_value = [(short_ha.value/short.value) *100,\n",
    "                      (medium_ha.value/medium.value) *100,\n",
    "                      (tall_ha.value/tall.value) *100]\n",
    "\n",
    "percentage_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STORE DATAFRAME TO FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'player_fifa_api_id',\n",
       " 'player_api_id',\n",
       " 'date',\n",
       " 'overall_rating',\n",
       " 'potential',\n",
       " 'preferred_foot',\n",
       " 'attacking_work_rate',\n",
       " 'defensive_work_rate',\n",
       " 'crossing',\n",
       " 'finishing',\n",
       " 'heading_accuracy',\n",
       " 'short_passing',\n",
       " 'volleys',\n",
       " 'dribbling',\n",
       " 'curve',\n",
       " 'free_kick_accuracy',\n",
       " 'long_passing',\n",
       " 'ball_control',\n",
       " 'acceleration',\n",
       " 'sprint_speed',\n",
       " 'agility',\n",
       " 'reactions',\n",
       " 'balance',\n",
       " 'shot_power',\n",
       " 'jumping',\n",
       " 'stamina',\n",
       " 'strength',\n",
       " 'long_shots',\n",
       " 'aggression',\n",
       " 'interceptions',\n",
       " 'positioning',\n",
       " 'vision',\n",
       " 'penalties',\n",
       " 'marking',\n",
       " 'standing_tackle',\n",
       " 'sliding_tackle',\n",
       " 'gk_diving',\n",
       " 'gk_handling',\n",
       " 'gk_kicking',\n",
       " 'gk_positioning',\n",
       " 'gk_reflexes',\n",
       " 'year']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa_2016.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pa_2016.select( 'player_api_id','date')\\\n",
    "        .coalesce(1)\\\n",
    "        .write\\\n",
    "        .option(\"header\",\"true\")\\\n",
    "        .csv(\"file:///home/icpl12900/Desktop/assignments/Spark_data/player_date.csv\")\n",
    "        \n",
    "#coalesce(1) --- to repartitioned DataFrame to single partition, to write into single file. here we want \n",
    "#one partition  so use 1 as argument\n",
    "#player_date.csv it is directiory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USE CUSTOM ACCUMULATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.accumulators import AccumulatorParam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VectorAccumulator(AccumulatorParam):\n",
    "    def zero(self,value):\n",
    "        return [0.0] * len(value)\n",
    "    def addInPlace(self,v1,v2):\n",
    "        for i in range(len(v1)):\n",
    "            v1[i] += v2[i]\n",
    "        return v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.0, 20.0]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_acc = sc.accumulator([10.0,20.0],VectorAccumulator())\n",
    "vector_acc.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## BASIC SQL OPERATIONS ON SPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, player_fifa_api_id: string, player_api_id: string, date: string, overall_rating: string, potential: string, preferred_foot: string, attacking_work_rate: string, defensive_work_rate: string, crossing: string, finishing: string, heading_accuracy: string, short_passing: string, volleys: string, dribbling: string, curve: string, free_kick_accuracy: string, long_passing: string, ball_control: string, acceleration: string, sprint_speed: string, agility: string, reactions: string, balance: string, shot_power: string, jumping: string, stamina: string, strength: string, long_shots: string, aggression: string, interceptions: string, positioning: string, vision: string, penalties: string, marking: string, standing_tackle: string, sliding_tackle: string, gk_diving: string, gk_handling: string, gk_kicking: string, gk_positioning: string, gk_reflexes: string, year: string]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pa_2016.createOrReplaceTempView('table_2016')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It create temporary view for dataFrame pa_2016 and it is temporary . It create only for this session. Once session is closed view also disappear\n",
    "#### It Register DataFrame as Table For Per-Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data = sqlContext.sql(\"select * from table_2016\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-------------+-------------------+--------------+---------+--------------+-------------------+-------------------+--------+---------+----------------+-------------+-------+---------+-----+------------------+------------+------------+------------+------------+-------+---------+-------+----------+-------+-------+--------+----------+----------+-------------+-----------+------+---------+-------+---------------+--------------+---------+-----------+----------+--------------+-----------+----+\n",
      "| id|player_fifa_api_id|player_api_id|               date|overall_rating|potential|preferred_foot|attacking_work_rate|defensive_work_rate|crossing|finishing|heading_accuracy|short_passing|volleys|dribbling|curve|free_kick_accuracy|long_passing|ball_control|acceleration|sprint_speed|agility|reactions|balance|shot_power|jumping|stamina|strength|long_shots|aggression|interceptions|positioning|vision|penalties|marking|standing_tackle|sliding_tackle|gk_diving|gk_handling|gk_kicking|gk_positioning|gk_reflexes|year|\n",
      "+---+------------------+-------------+-------------------+--------------+---------+--------------+-------------------+-------------------+--------+---------+----------------+-------------+-------+---------+-----+------------------+------------+------------+------------+------------+-------+---------+-------+----------+-------+-------+--------+----------+----------+-------------+-----------+------+---------+-------+---------------+--------------+---------+-----------+----------+--------------+-----------+----+\n",
      "|  1|            218353|       505942|2016-02-18 00:00:00|            67|       71|         right|             medium|             medium|      49|       44|              71|           61|     44|       51|   45|                39|          64|          49|          60|          64|     59|       47|     65|        55|     58|     54|      76|        35|        71|           70|         45|    54|       48|     65|             69|            69|        6|         11|        10|             8|          8|2016|\n",
      "+---+------------------+-------------+-------------------+--------------+---------+--------------+-------------------+-------------------+--------+---------+----------------+-------------+-------+---------+-----+------------------+------------+------------+------------+------------+-------+---------+-------+----------+-------+-------+--------+----------+----------+-------------+-----------+------+---------+-------+---------------+--------------+---------+-----------+----------+--------------+-----------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_data.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  1|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('select id from table_2016 where id == 1').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To make avaliable Global table to all SPARK SESSION  use \"createGlobalTempView\"\n",
    "#### And to access this global table use  \"global_temp.tableName\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pa_2016.createGlobalTempView('table_2016')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-------------+-------------------+--------------+---------+--------------+-------------------+-------------------+--------+---------+----------------+-------------+-------+---------+-----+------------------+------------+------------+------------+------------+-------+---------+-------+----------+-------+-------+--------+----------+----------+-------------+-----------+------+---------+-------+---------------+--------------+---------+-----------+----------+--------------+-----------+----+\n",
      "| id|player_fifa_api_id|player_api_id|               date|overall_rating|potential|preferred_foot|attacking_work_rate|defensive_work_rate|crossing|finishing|heading_accuracy|short_passing|volleys|dribbling|curve|free_kick_accuracy|long_passing|ball_control|acceleration|sprint_speed|agility|reactions|balance|shot_power|jumping|stamina|strength|long_shots|aggression|interceptions|positioning|vision|penalties|marking|standing_tackle|sliding_tackle|gk_diving|gk_handling|gk_kicking|gk_positioning|gk_reflexes|year|\n",
      "+---+------------------+-------------+-------------------+--------------+---------+--------------+-------------------+-------------------+--------+---------+----------------+-------------+-------+---------+-----+------------------+------------+------------+------------+------------+-------+---------+-------+----------+-------+-------+--------+----------+----------+-------------+-----------+------+---------+-------+---------------+--------------+---------+-----------+----------+--------------+-----------+----+\n",
      "|  1|            218353|       505942|2016-02-18 00:00:00|            67|       71|         right|             medium|             medium|      49|       44|              71|           61|     44|       51|   45|                39|          64|          49|          60|          64|     59|       47|     65|        55|     58|     54|      76|        35|        71|           70|         45|    54|       48|     65|             69|            69|        6|         11|        10|             8|          8|2016|\n",
      "+---+------------------+-------------+-------------------+--------------+---------+--------------+-------------------+-------------------+--------+---------+----------------+-------------+-------+---------+-----+------------------+------------+------------+------------+------------+-------+---------+-------+----------+-------+-------+--------+----------+----------+-------------+-----------+------+---------+-------+---------------+--------------+---------+-----------+----------+--------------+-----------+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"select * from global_temp.table_2016\").show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AirLine DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airlinesPath = 'file:///home/icpl12900/Desktop/assignments/Spark_data/airline.csv'\n",
    "flightPath = 'file:///home/icpl12900/Desktop/assignments/Spark_data/flights.csv'\n",
    "airportPath = 'file:///home/icpl12900/Desktop/assignments/Spark_data/airports.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "airline = spark.read.format(\"csv\")\\\n",
    "                .option(\"header\",\"true\")\\\n",
    "                .load(airlinesPath)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airport = spark.read.format(\"csv\")\\\n",
    "                .option(\"header\",\"true\")\\\n",
    "                .load(airportPath)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flight = spark.read.format(\"csv\")\\\n",
    "                .option(\"header\",\"true\")\\\n",
    "                .load(flightPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[date: string, airlines: string, flight_number: string, origin: string, destination: string, departure: string, departure_delay: string, arrival: string, arrival_delay: string, air_time: string, distance: string]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------------+------+-----------+---------+---------------+-------+-------------+--------+--------+\n",
      "|      date|airlines|flight_number|origin|destination|departure|departure_delay|arrival|arrival_delay|air_time|distance|\n",
      "+----------+--------+-------------+------+-----------+---------+---------------+-------+-------------+--------+--------+\n",
      "|2014-04-01|   19805|            1|   JFK|        LAX|     0854|          -6.00|   1217|         2.00|  355.00| 2475.00|\n",
      "+----------+--------+-------------+------+-----------+---------+---------------+-------+-------------+--------+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airline.createOrReplaceTempView('airline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airport.createOrReplaceTempView('airport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flight.createOrReplaceTempView('flight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', 'Private flight', '\\\\N', '-', 'N/A', '_c5', '_c6', 'Y']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Code', 'Description']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'airlines',\n",
       " 'flight_number',\n",
       " 'origin',\n",
       " 'destination',\n",
       " 'departure',\n",
       " 'departure_delay',\n",
       " 'arrival',\n",
       " 'arrival_delay',\n",
       " 'air_time',\n",
       " 'distance']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|airlines|\n",
      "+--------+\n",
      "|   19805|\n",
      "+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql(\"select airlines from flight\").show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Table is dataFrame so we can use SQL Query as well as DataFrame operations on it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We want to calculate Total distance for All Flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_distance = sqlContext.sql(\"select distance from flight\")\\\n",
    "                            .agg({\"distance\":\"sum\"})\\\n",
    "                            .withColumnRenamed(\"sum(distance)\",\"total_distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|total_distance|\n",
      "+--------------+\n",
      "|  3.79052917E8|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_distance.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If we want to calculate Total Distance for Particular Airline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_distance_per_airline = sqlContext.sql(\"select airlines,distance from flight\")\\\n",
    "                            .groupBy(\"airlines\")\\\n",
    "                            .agg({\"distance\":\"sum\"})\\\n",
    "                            .withColumnRenamed(\"sum(distance)\",\"total_distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|airlines|total_distance|\n",
      "+--------+--------------+\n",
      "|   19690|     3317412.0|\n",
      "+--------+--------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_distance_per_airline.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Departure_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'airlines',\n",
       " 'flight_number',\n",
       " 'origin',\n",
       " 'destination',\n",
       " 'departure',\n",
       " 'departure_delay',\n",
       " 'arrival',\n",
       " 'arrival_delay',\n",
       " 'air_time',\n",
       " 'distance']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_delay_2014 = sqlContext.sql('select date,airlines,departure_delay from flight where departure_delay >0 and year(date) = 2014')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------------+\n",
      "|      date|airlines|departure_delay|\n",
      "+----------+--------+---------------+\n",
      "|2014-04-01|   19805|          14.00|\n",
      "+----------+--------+---------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_delay_2014.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[date: string, airlines: string, departure_delay: string]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_delay_2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_delay_2014.createOrReplaceTempView('all_delay_2014_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------------+\n",
      "|      date|airlines|departure_delay|\n",
      "+----------+--------+---------------+\n",
      "|2014-04-18|   20409|          99.00|\n",
      "+----------+--------+---------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_delay_2014.orderBy(all_delay_2014.departure_delay.desc()).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_delay_airlines = sqlContext.sql('select count(airlines) from all_delay_2014_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_no_delay = total_delay_airlines.collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179015"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_no_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_airlines = sqlContext.sql('select count(airlines) from flight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[count(airlines): bigint]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_airlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|count(airlines)|\n",
      "+---------------+\n",
      "|         476881|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_airlines.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_flight = total_airlines.collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "476881"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_flight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percentage of total delay flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "percentage = float(total_no_delay) / float(total_flight) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.53871510922012"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Find Name of  Airline with Departure Delay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'airlines',\n",
       " 'flight_number',\n",
       " 'origin',\n",
       " 'destination',\n",
       " 'departure',\n",
       " 'departure_delay',\n",
       " 'arrival',\n",
       " 'arrival_delay',\n",
       " 'air_time',\n",
       " 'distance']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delay_airline = sqlContext.sql('select airlines,departure_delay from flight')\\\n",
    "                        .groupBy('airlines')\\\n",
    "                        .agg({'departure_delay':'avg'})\\\n",
    "                        .withColumnRenamed('avg(departure_delay)','departure_delay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[airlines: string, departure_delay: double]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delay_airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|airlines|    departure_delay|\n",
      "+--------+-------------------+\n",
      "|   19690|-2.1981308411214955|\n",
      "+--------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delay_airline.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "delay_airline_order = delay_airline.orderBy(delay_airline.departure_delay.desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|airlines|    departure_delay|\n",
      "+--------+-------------------+\n",
      "|   19393| 13.429567657134724|\n",
      "|   20366| 12.296210112379818|\n",
      "|   19977|  8.818392620527979|\n",
      "|   20436|  8.716275167785234|\n",
      "|   20409|   8.31110357194785|\n",
      "|   20398|  7.372135487994157|\n",
      "|   21171|  6.989682212133719|\n",
      "|   19805|  6.733031255779545|\n",
      "|   20304|   6.05227892794094|\n",
      "|   19790|  5.597661140117859|\n",
      "|   20437|  5.110621095185594|\n",
      "|   20355| 3.9925874044242105|\n",
      "|   19930|-0.6991515343747522|\n",
      "|   19690|-2.1981308411214955|\n",
      "+--------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delay_airline_order.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WINDOW FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### +----+----+----+----------+----------+\n",
    "\n",
    "#### |col1|col2|rank|dense_rank|row_number|\n",
    "\n",
    "#### +----+----+----+----------+----------+\n",
    "\n",
    "#### |   a|  10|   1|         1|         1|\n",
    "\n",
    "#### |   a|  10|   1|         1|         2|\n",
    "\n",
    "#### |   a|  20|   3|         2|         3|\n",
    "\n",
    "#### +----+----+----+----------+----------+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "product = spark.read.format(\"csv\")\\\n",
    "                .option(\"header\",\"true\")\\\n",
    "                .load('file:///home/icpl12900/Desktop/assignments/Spark_data/products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[product: string, category: string, price: string]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_product = Window.partitionBy(product['category'])\\\n",
    "                        .orderBy(product['price'].desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.window.WindowSpec at 0x7f8ccb125c50>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "price_rank = (func.rank().over(window_product))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<RANK() OVER (PARTITION BY category ORDER BY price DESC NULLS LAST UnspecifiedFrame)>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RANK()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "product_rank = product.select(product['product'],product['category'],product['price'])\\\n",
    "                    .withColumn('rank',func.rank().over(window_product))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[product: string, category: string, price: string, rank: int]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-----+----+\n",
      "|   product|category|price|rank|\n",
      "+----------+--------+-----+----+\n",
      "|    iPhone|  Mobile|  999|   1|\n",
      "|Samsung JX|  Mobile|  799|   2|\n",
      "|Redmi Note|  Mobile|  399|   3|\n",
      "|   OnePlus|  Mobile|  356|   4|\n",
      "|        Mi|  Mobile|  299|   5|\n",
      "|  Micromax|  Mobile|  249|   6|\n",
      "|Samsung TX|  Tablet|  999|   1|\n",
      "|      iPad|  Tablet|  789|   2|\n",
      "|    Lenovo|  Tablet|  499|   3|\n",
      "|        Xu|  Tablet|  267|   4|\n",
      "+----------+--------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_rank.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROWBETWEEN(-1,0)\n",
    "##### Here we create window of current row and one before current row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "window_product_row = Window.partitionBy(product['category'])\\\n",
    "                        .orderBy(product['price'].desc())\\\n",
    "                        .rowsBetween(-1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.window.WindowSpec at 0x7f8ccb096810>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_product_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "price_max = (func.max(product['price']).over(window_product_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<max(price) OVER (PARTITION BY category ORDER BY price DESC NULLS LAST ROWS BETWEEN 1 PRECEDING AND CURRENT ROW)>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-----+---------+\n",
      "|   product|category|price|price_max|\n",
      "+----------+--------+-----+---------+\n",
      "|    iPhone|  Mobile|  999|      999|\n",
      "|Samsung JX|  Mobile|  799|      999|\n",
      "|Redmi Note|  Mobile|  399|      799|\n",
      "|   OnePlus|  Mobile|  356|      399|\n",
      "|        Mi|  Mobile|  299|      356|\n",
      "|  Micromax|  Mobile|  249|      299|\n",
      "|Samsung TX|  Tablet|  999|      999|\n",
      "|      iPad|  Tablet|  789|      999|\n",
      "|    Lenovo|  Tablet|  499|      789|\n",
      "|        Xu|  Tablet|  267|      499|\n",
      "+----------+--------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product.select(product['product'],product['category'],product['price'],price_max.alias(\"price_max\")).show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rowsBetween(-1,1)\n",
    "##### Here we select before , current, after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_product_row = Window.partitionBy(product['category'])\\\n",
    "                        .orderBy(product['price'].desc())\\\n",
    "                        .rowsBetween(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "price_max = (func.max(product['price']).over(window_product_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-----+---------+\n",
      "|   product|category|price|price_max|\n",
      "+----------+--------+-----+---------+\n",
      "|    iPhone|  Mobile|  999|      999|\n",
      "|Samsung JX|  Mobile|  799|      999|\n",
      "|Redmi Note|  Mobile|  399|      799|\n",
      "|   OnePlus|  Mobile|  356|      399|\n",
      "|        Mi|  Mobile|  299|      356|\n",
      "|  Micromax|  Mobile|  249|      299|\n",
      "|Samsung TX|  Tablet|  999|      999|\n",
      "|      iPad|  Tablet|  789|      999|\n",
      "|    Lenovo|  Tablet|  499|      789|\n",
      "|        Xu|  Tablet|  267|      499|\n",
      "+----------+--------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product.select(product['product'],product['category'],product['price'],price_max.alias(\"price_max\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rowsBetween(-sys.maxsize,sys.maxsize)\n",
    "##### It select all rows within that partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_product_row = Window.partitionBy(product['category'])\\\n",
    "                        .orderBy(product['price'].desc())\\\n",
    "                        .rowsBetween(-sys.maxsize,sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "price_max = (func.max(product['price']).over(window_product_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-----+---------+\n",
      "|   product|category|price|price_max|\n",
      "+----------+--------+-----+---------+\n",
      "|    iPhone|  Mobile|  999|      999|\n",
      "|Samsung JX|  Mobile|  799|      999|\n",
      "|Redmi Note|  Mobile|  399|      999|\n",
      "|   OnePlus|  Mobile|  356|      999|\n",
      "|        Mi|  Mobile|  299|      999|\n",
      "|  Micromax|  Mobile|  249|      999|\n",
      "|Samsung TX|  Tablet|  999|      999|\n",
      "|      iPad|  Tablet|  789|      999|\n",
      "|    Lenovo|  Tablet|  499|      999|\n",
      "|        Xu|  Tablet|  267|      999|\n",
      "+----------+--------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product.select(product['product'],product['category'],product['price'],price_max.alias(\"price_max\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rangeBetween(-sys.maxsize,sys.maxsize)\n",
    "##### It select all rows within that partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_product_row = Window.partitionBy(product['category'])\\\n",
    "                        .orderBy(product['price'].desc())\\\n",
    "                        .rangeBetween(-sys.maxsize,sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "price_max = (func.max(product['price']).over(window_product_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-----+---------+\n",
      "|   product|category|price|price_max|\n",
      "+----------+--------+-----+---------+\n",
      "|    iPhone|  Mobile|  999|      999|\n",
      "|Samsung JX|  Mobile|  799|      999|\n",
      "|Redmi Note|  Mobile|  399|      999|\n",
      "|   OnePlus|  Mobile|  356|      999|\n",
      "|        Mi|  Mobile|  299|      999|\n",
      "|  Micromax|  Mobile|  249|      999|\n",
      "|Samsung TX|  Tablet|  999|      999|\n",
      "|      iPad|  Tablet|  789|      999|\n",
      "|    Lenovo|  Tablet|  499|      999|\n",
      "|        Xu|  Tablet|  267|      999|\n",
      "+----------+--------+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product.select(product['product'],product['category'],product['price'],price_max.alias(\"price_max\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRODUCT PRICE DIFFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "price_difference = (func.max(product['price']).over(window_product_row)  - product['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-----+----------------+\n",
      "|   product|category|price|price_difference|\n",
      "+----------+--------+-----+----------------+\n",
      "|    iPhone|  Mobile|  999|             0.0|\n",
      "|Samsung JX|  Mobile|  799|           200.0|\n",
      "|Redmi Note|  Mobile|  399|           600.0|\n",
      "|   OnePlus|  Mobile|  356|           643.0|\n",
      "|        Mi|  Mobile|  299|           700.0|\n",
      "|  Micromax|  Mobile|  249|           750.0|\n",
      "|Samsung TX|  Tablet|  999|             0.0|\n",
      "|      iPad|  Tablet|  789|           210.0|\n",
      "|    Lenovo|  Tablet|  499|           500.0|\n",
      "|        Xu|  Tablet|  267|           732.0|\n",
      "+----------+--------+-----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product.select(product['product'],product['category'],product['price'],price_difference.alias(\"price_difference\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
